<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Webcam Display with Pose Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
    <script defer src="https://www.gstatic.com/firebasejs/8.10.1/firebase-app.js"></script>
    <script defer src="https://www.gstatic.com/firebasejs/8.10.1/firebase-auth.js"></script>
    <script defer src="https://www.gstatic.com/firebasejs/8.10.1/firebase-database.js"></script>
    <script src="firebase.js"></script>
    <style>
        #videoContainer {
            display: flex;
            justify-content: space-around;
        }
        video {
            max-width: 50%;
        }
    </style>
</head>
<body>
    <h1>Webcam Display with Pose Detection</h1>
    <div id="videoContainer">
        <div>
            <h2>Webcam Feed</h2>
            <video id="videoElement" autoplay></video>
            <button id="startButton" onclick="startWebcam()">Start Webcam</button>
            <input type="text" id="testFirebaseInput" name="input">
            <button id="asdf" onclick="pushStretchR(1)">push text value to id 1:</button>
            <button id="stopButton" onclick="stopWebcam()" style="display: none;">Stop Webcam</button>
        </div>
        <div>
            <h2>Pose Detection</h2>
            <canvas id="outputCanvas" width="640" height="480"></canvas>
        </div>
    </div>

    <script>
        let videoElement, outputCanvas, net;

        async function startWebcam() {
            videoElement = document.getElementById('videoElement');
            outputCanvas = document.getElementById('outputCanvas');

            // Access webcam
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            videoElement.srcObject = stream;

            // Load PoseNet model
            net = await posenet.load();

            // Enable/disable buttons
            document.getElementById('startButton').style.display = 'none';
            document.getElementById('stopButton').style.display = 'inline-block';

            detectPose();
        }

        function stopWebcam() {
            const stream = videoElement.srcObject;
            const tracks = stream.getTracks();

            tracks.forEach(track => track.stop());

            // Enable/disable buttons
            document.getElementById('startButton').style.display = 'inline-block';
            document.getElementById('stopButton').style.display = 'none';
        }

        async function detectPose() {
            const videoWidth = videoElement.videoWidth;
            const videoHeight = videoElement.videoHeight;

            outputCanvas.width = videoWidth;
            outputCanvas.height = videoHeight;

            const ctx = outputCanvas.getContext('2d');

            async function poseDetectionFrame() {
                // Estimate poses
                const poses = await net.estimatePoses(videoElement, {
                    flipHorizontal: false,
                    decodingMethod: 'single-person'
                });

                // Draw poses
                ctx.clearRect(0, 0, videoWidth, videoHeight);
                poses.forEach(({ score, keypoints }) => {
                    if (score >= 0.5) {
                        // Draw keypoints
                        keypoints.forEach(({ position }) => {
                            ctx.beginPath();
                            ctx.arc(position.x, position.y, 3, 0, 2 * Math.PI);
                            ctx.fillStyle = 'red';
                            ctx.fill();
                        });
                    }
                });

                requestAnimationFrame(poseDetectionFrame);
            }

            poseDetectionFrame();
        }
    </script>
</body>
</html>
